{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a2b5df1-a1ce-4f3d-8d96-f97111170a67",
   "metadata": {},
   "source": [
    "- Use GPS Gridder from GMT to interpolate between GPS stations\n",
    "- The algorithm is based on the greens functions for elastic sheets with a given Poisson's ratio. \n",
    "- From: Sandwell, D. T., and P. Wessel (2016), Interpolation of 2-D vector data using constraints from elasticity, Geophys. Res.Lett."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0e2400-30ac-4e90-a21f-28b90a14188c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import subprocess\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import subprocess\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20cd23af-5088-421e-95a2-8e8e3de65cff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: /Users/zuhair/Library/CloudStorage/OneDrive-NanyangTechnologicalUniversity/Research/current-projects/strain-rate-seismicity/ntbk\n"
     ]
    }
   ],
   "source": [
    "# Get the current working directory\n",
    "current_directory = os.getcwd()\n",
    "\n",
    "# Print the current directory\n",
    "print(\"Current Working Directory:\", current_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1926f343-048d-4b1a-ae3a-82a65c9824ef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing strain via gpsgridder method.\n",
      "gmt gpsgridder tempgps.txt -R94.95/98.05/15.95/28.05 -I0.1/0.1 -S0.5 -Fd0.01 -C0.0001 -Emisfitfile.txt -fg -r -Gnc_%s.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpsgridder [ERROR]: Data constraint 16 and 12 occupy the same location but differ in observation (27.5981370215/27.5740525441 vs 22.7285171622/22.7080989853)\n",
      "gpsgridder [ERROR]: Data constraint 18 and 7 occupy the same location but differ in observation (32.2083030335/30.5491834 vs 13.0047082267/12.079911776)\n",
      "gpsgridder [WARNING]: Found 2 data constraint duplicates with different observation values\n",
      "gpsgridder [WARNING]: Expect some eigenvalues to be identically zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success computing strain via gpsgridder method.\n",
      "Computing strain via gpsgridder method.\n",
      "gmt gpsgridder tempgps.txt -R94.85/98.15/15.85/28.15 -I0.3/0.3 -S0.5 -Fd0.01 -C0.0001 -Emisfitfile.txt -fg -r -Gnc_%s.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpsgridder [ERROR]: Data constraint 16 and 12 occupy the same location but differ in observation (27.5981370215/27.5740525441 vs 22.7285171622/22.7080989853)\n",
      "gpsgridder [ERROR]: Data constraint 18 and 7 occupy the same location but differ in observation (32.2083030335/30.5491834 vs 13.0047082267/12.079911776)\n",
      "gpsgridder [WARNING]: Found 2 data constraint duplicates with different observation values\n",
      "gpsgridder [WARNING]: Expect some eigenvalues to be identically zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success computing strain via gpsgridder method.\n",
      "Computing strain via gpsgridder method.\n",
      "gmt gpsgridder tempgps.txt -R94.75/98.25/15.75/28.25 -I0.5/0.5 -S0.5 -Fd0.01 -C0.0001 -Emisfitfile.txt -fg -r -Gnc_%s.nc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "gpsgridder [ERROR]: Data constraint 16 and 12 occupy the same location but differ in observation (27.5981370215/27.5740525441 vs 22.7285171622/22.7080989853)\n",
      "gpsgridder [ERROR]: Data constraint 18 and 7 occupy the same location but differ in observation (32.2083030335/30.5491834 vs 13.0047082267/12.079911776)\n",
      "gpsgridder [WARNING]: Found 2 data constraint duplicates with different observation values\n",
      "gpsgridder [WARNING]: Expect some eigenvalues to be identically zero\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: '/Users/zuhair/Library/CloudStorage/OneDrive-NanyangTechnologicalUniversity/Research/current-projects/strain-rate-seismicity/ntbk/Output_gpsgridder/I0.5_max_shear.nc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/file_manager.py:211\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 211\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_key]\n\u001b[1;32m    212\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/lru_cache.py:56\u001b[0m, in \u001b[0;36mLRUCache.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m---> 56\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[key]\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache\u001b[38;5;241m.\u001b[39mmove_to_end(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: [<class 'netCDF4._netCDF4.Dataset'>, ('/Users/zuhair/Library/CloudStorage/OneDrive-NanyangTechnologicalUniversity/Research/current-projects/strain-rate-seismicity/ntbk/Output_gpsgridder/I0.5_max_shear.nc',), 'a', (('clobber', True), ('diskless', False), ('format', 'NETCDF4'), ('persist', False)), '20da65f9-c252-4944-a899-d5ea1c080b8f']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 156\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;66;03m# Initialize and compute strain using gpsgridder\u001b[39;00m\n\u001b[1;32m    155\u001b[0m strain_model \u001b[38;5;241m=\u001b[39m gpsgridder(params)\n\u001b[0;32m--> 156\u001b[0m max_shear_grd \u001b[38;5;241m=\u001b[39m strain_model\u001b[38;5;241m.\u001b[39mcompute(vel_field_data)\n",
      "Cell \u001b[0;32mIn[3], line 72\u001b[0m, in \u001b[0;36mgpsgridder.compute\u001b[0;34m(self, myVelfield)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute\u001b[39m(\u001b[38;5;28mself\u001b[39m, myVelfield):\n\u001b[0;32m---> 72\u001b[0m     Ve, Vn, rot_grd, exx_grd, exy_grd, eyy_grd, max_shear_grd, dilatation_grd, second_invariant_grd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_gpsgridder(myVelfield)\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m max_shear_grd\n",
      "Cell \u001b[0;32mIn[3], line 109\u001b[0m, in \u001b[0;36mgpsgridder.compute_gpsgridder\u001b[0;34m(self, myVelfield)\u001b[0m\n\u001b[1;32m    107\u001b[0m max_shear_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmax_shear\u001b[39m\u001b[38;5;124m\"\u001b[39m: max_shear_da})\n\u001b[1;32m    108\u001b[0m max_shear_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tempdir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mI\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_grid_inc[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_max_shear.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 109\u001b[0m max_shear_ds\u001b[38;5;241m.\u001b[39mto_netcdf(max_shear_file)\n\u001b[1;32m    111\u001b[0m dilatation_da \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataArray(dilatation, coords\u001b[38;5;241m=\u001b[39m[ydata_adjusted, xdata_adjusted], dims\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlatitude\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlongitude\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    112\u001b[0m dilatation_ds \u001b[38;5;241m=\u001b[39m xr\u001b[38;5;241m.\u001b[39mDataset({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdilatation\u001b[39m\u001b[38;5;124m\"\u001b[39m: dilatation_da})\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/core/dataset.py:1957\u001b[0m, in \u001b[0;36mDataset.to_netcdf\u001b[0;34m(self, path, mode, format, group, engine, encoding, unlimited_dims, compute, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1954\u001b[0m     encoding \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m   1955\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxarray\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackends\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m to_netcdf\n\u001b[0;32m-> 1957\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m to_netcdf(  \u001b[38;5;66;03m# type: ignore  # mypy cannot resolve the overloads:(\u001b[39;00m\n\u001b[1;32m   1958\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1959\u001b[0m     path,\n\u001b[1;32m   1960\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[1;32m   1961\u001b[0m     \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m,\n\u001b[1;32m   1962\u001b[0m     group\u001b[38;5;241m=\u001b[39mgroup,\n\u001b[1;32m   1963\u001b[0m     engine\u001b[38;5;241m=\u001b[39mengine,\n\u001b[1;32m   1964\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m   1965\u001b[0m     unlimited_dims\u001b[38;5;241m=\u001b[39munlimited_dims,\n\u001b[1;32m   1966\u001b[0m     compute\u001b[38;5;241m=\u001b[39mcompute,\n\u001b[1;32m   1967\u001b[0m     multifile\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1968\u001b[0m     invalid_netcdf\u001b[38;5;241m=\u001b[39minvalid_netcdf,\n\u001b[1;32m   1969\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/api.py:1255\u001b[0m, in \u001b[0;36mto_netcdf\u001b[0;34m(dataset, path_or_file, mode, format, group, engine, encoding, unlimited_dims, compute, multifile, invalid_netcdf)\u001b[0m\n\u001b[1;32m   1251\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1252\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1253\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munrecognized option \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minvalid_netcdf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m for engine \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mengine\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1254\u001b[0m         )\n\u001b[0;32m-> 1255\u001b[0m store \u001b[38;5;241m=\u001b[39m store_open(target, mode, \u001b[38;5;28mformat\u001b[39m, group, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1257\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m unlimited_dims \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1258\u001b[0m     unlimited_dims \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mencoding\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munlimited_dims\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:391\u001b[0m, in \u001b[0;36mNetCDF4DataStore.open\u001b[0;34m(cls, filename, mode, format, group, clobber, diskless, persist, lock, lock_maker, autoclose)\u001b[0m\n\u001b[1;32m    385\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    386\u001b[0m     clobber\u001b[38;5;241m=\u001b[39mclobber, diskless\u001b[38;5;241m=\u001b[39mdiskless, persist\u001b[38;5;241m=\u001b[39mpersist, \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mformat\u001b[39m\n\u001b[1;32m    387\u001b[0m )\n\u001b[1;32m    388\u001b[0m manager \u001b[38;5;241m=\u001b[39m CachingFileManager(\n\u001b[1;32m    389\u001b[0m     netCDF4\u001b[38;5;241m.\u001b[39mDataset, filename, mode\u001b[38;5;241m=\u001b[39mmode, kwargs\u001b[38;5;241m=\u001b[39mkwargs\n\u001b[1;32m    390\u001b[0m )\n\u001b[0;32m--> 391\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(manager, group\u001b[38;5;241m=\u001b[39mgroup, mode\u001b[38;5;241m=\u001b[39mmode, lock\u001b[38;5;241m=\u001b[39mlock, autoclose\u001b[38;5;241m=\u001b[39mautoclose)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:338\u001b[0m, in \u001b[0;36mNetCDF4DataStore.__init__\u001b[0;34m(self, manager, group, mode, lock, autoclose)\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group \u001b[38;5;241m=\u001b[39m group\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 338\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mdata_model\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mds\u001b[38;5;241m.\u001b[39mfilepath()\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_remote \u001b[38;5;241m=\u001b[39m is_remote_uri(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filename)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:400\u001b[0m, in \u001b[0;36mNetCDF4DataStore.ds\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mds\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/netCDF4_.py:394\u001b[0m, in \u001b[0;36mNetCDF4DataStore._acquire\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_acquire\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[0;32m--> 394\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_manager\u001b[38;5;241m.\u001b[39macquire_context(needs_lock) \u001b[38;5;28;01mas\u001b[39;00m root:\n\u001b[1;32m    395\u001b[0m         ds \u001b[38;5;241m=\u001b[39m _nc4_require_group(root, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_group, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode)\n\u001b[1;32m    396\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ds\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/file_manager.py:199\u001b[0m, in \u001b[0;36mCachingFileManager.acquire_context\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[38;5;129m@contextlib\u001b[39m\u001b[38;5;241m.\u001b[39mcontextmanager\n\u001b[1;32m    197\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21macquire_context\u001b[39m(\u001b[38;5;28mself\u001b[39m, needs_lock\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[1;32m    198\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Context manager for acquiring a file.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m     file, cached \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_acquire_with_cache_info(needs_lock)\n\u001b[1;32m    200\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    201\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m file\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/xarray/backends/file_manager.py:217\u001b[0m, in \u001b[0;36mCachingFileManager._acquire_with_cache_info\u001b[0;34m(self, needs_lock)\u001b[0m\n\u001b[1;32m    215\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m kwargs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m    216\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode\n\u001b[0;32m--> 217\u001b[0m file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_opener(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    219\u001b[0m     \u001b[38;5;66;03m# ensure file doesn't get overridden when opened again\u001b[39;00m\n\u001b[1;32m    220\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2469\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4.Dataset.__init__\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32msrc/netCDF4/_netCDF4.pyx:2028\u001b[0m, in \u001b[0;36mnetCDF4._netCDF4._ensure_nc_success\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: '/Users/zuhair/Library/CloudStorage/OneDrive-NanyangTechnologicalUniversity/Research/current-projects/strain-rate-seismicity/ntbk/Output_gpsgridder/I0.5_max_shear.nc'"
     ]
    }
   ],
   "source": [
    "# Define utility functions\n",
    "def filter_by_bounding_box(velfield, bounding_box):\n",
    "    \"\"\"Filter the velocity field data by a given bounding box.\"\"\"\n",
    "    filtered = velfield[\n",
    "        (velfield['Lon'] >= bounding_box[0]) &\n",
    "        (velfield['Lon'] <= bounding_box[1]) &\n",
    "        (velfield['Lat'] >= bounding_box[2]) &\n",
    "        (velfield['Lat'] <= bounding_box[3])\n",
    "    ]\n",
    "    return filtered\n",
    "\n",
    "def create_model_velfield(xdata, ydata, Ve, Vn, observed_velfield):\n",
    "    \"\"\"Create a model velocity field based on the interpolated velocities.\"\"\"\n",
    "    model_velfield = observed_velfield.copy()\n",
    "    model_velfield['Ve'] = Ve.flatten()\n",
    "    model_velfield['Vn'] = Vn.flatten()\n",
    "    return model_velfield\n",
    "\n",
    "def subtract_two_velfields(observed_velfield, model_velfield):\n",
    "    \"\"\"Subtract two velocity fields to get residual velocities.\"\"\"\n",
    "    residual_velfield = observed_velfield.copy()\n",
    "    residual_velfield['Ve'] = observed_velfield['Ve'] - model_velfield['Ve']\n",
    "    residual_velfield['Vn'] = observed_velfield['Vn'] - model_velfield['Vn']\n",
    "    return residual_velfield\n",
    "\n",
    "def get_string_range(range_values, x_buffer=0, y_buffer=0):\n",
    "    \"\"\"Get a range string for GMT commands.\"\"\"\n",
    "    return f\"{range_values[0]-x_buffer}/{range_values[1]+x_buffer}/{range_values[2]-y_buffer}/{range_values[3]+y_buffer}\"\n",
    "\n",
    "def get_string_inc(inc_values):\n",
    "    \"\"\"Get an increment string for GMT commands.\"\"\"\n",
    "    return f\"{inc_values[0]}/{inc_values[1]}\"\n",
    "\n",
    "def strain_on_regular_grid(xinc, yinc, udata, vdata):\n",
    "    \"\"\"Calculate strain tensor components on a regular grid and extend to dilatation and second invariant.\"\"\"\n",
    "    exx = np.gradient(udata, xinc, axis=1)  # Normal strain in the x-direction\n",
    "    eyy = np.gradient(vdata, yinc, axis=0)  # Normal strain in the y-direction\n",
    "    exy = 0.5 * (np.gradient(udata, yinc, axis=0) + np.gradient(vdata, xinc, axis=1))  # Shear strain\n",
    "    rot = 0.5 * (np.gradient(vdata, xinc, axis=1) - np.gradient(udata, yinc, axis=0))  # Rotational component\n",
    "    \n",
    "    max_shear = 0.5*(np.sqrt((exx - eyy)**2 + 4*exy**2)) ## Based on Maurer and Materna (2023)\n",
    "\n",
    "    # Calculate Dilatation\n",
    "    dilatation = exx + eyy\n",
    "    \n",
    "    # Calculate Second Invariant\n",
    "    second_invariant = np.sqrt((exx**2 + eyy**2 + 2*exy**2))\n",
    "#     second_invariant = 0.5 * ((exx * eyy) - (exy**2))\n",
    "    \n",
    "    return exx, eyy, exy, rot, max_shear, dilatation, second_invariant\n",
    "\n",
    "# Define the gpsgridder class\n",
    "class gpsgridder:\n",
    "    def __init__(self, params):\n",
    "        self._grid_inc = params['inc']\n",
    "        self._strain_range = params['range_strain']\n",
    "        self._xdata = params['xdata']\n",
    "        self._ydata = params['ydata']\n",
    "        self._tempdir = params['outdir']\n",
    "        self._poisson, self._fd, self._eigenvalue = self.verify_inputs_gpsgridder(params['method_specific'])\n",
    "\n",
    "    def verify_inputs_gpsgridder(self, method_specific_dict):\n",
    "        if 'poisson' not in method_specific_dict:\n",
    "            raise ValueError(\"gps_gridder requires poisson's ratio. Please add to method_specific config.\")\n",
    "        if 'fd' not in method_specific_dict:\n",
    "            raise ValueError(\"gps_gridder requires fudge factor fd. Please add to method_specific config.\")\n",
    "        if 'eigenvalue' not in method_specific_dict:\n",
    "            raise ValueError(\"gps_gridder requires eigenvalue. Please add to method_specific config.\")\n",
    "        return method_specific_dict[\"poisson\"], method_specific_dict[\"fd\"], method_specific_dict[\"eigenvalue\"]\n",
    "\n",
    "    def compute(self, myVelfield):\n",
    "        Ve, Vn, rot_grd, exx_grd, exy_grd, eyy_grd, max_shear_grd, dilatation_grd, second_invariant_grd = self.compute_gpsgridder(myVelfield)\n",
    "        return max_shear_grd\n",
    "\n",
    "    def compute_gpsgridder(self, myVelfield):\n",
    "        print(\"Computing strain via gpsgridder method.\")\n",
    "        myVelfield.to_csv(\"tempgps.txt\", sep=' ', index=False, header=False)\n",
    "        command = f\"gmt gpsgridder tempgps.txt -R{get_string_range(self._strain_range, self._grid_inc[0]/2, self._grid_inc[1]/2)} -I{get_string_inc(self._grid_inc)} -S{self._poisson} -Fd{self._fd} -C{self._eigenvalue} -Emisfitfile.txt -fg -r -Gnc_%s.nc\"\n",
    "        print(command)\n",
    "        subprocess.call(command, shell=True)\n",
    "\n",
    "        subprocess.call(['rm', 'tempgps.txt'], shell=False)\n",
    "        subprocess.call(['rm', 'gmt.history'], shell=False)\n",
    "        subprocess.call(['mv', 'misfitfile.txt', self._tempdir], shell=False)\n",
    "        subprocess.call(['mv', 'nc_u.nc', self._tempdir], shell=False)\n",
    "        subprocess.call(['mv', 'nc_v.nc', self._tempdir], shell=False)\n",
    "\n",
    "        file1 = os.path.join(self._tempdir, \"nc_u.nc\")\n",
    "        file2 = os.path.join(self._tempdir, \"nc_v.nc\")\n",
    "        ds_u = xr.open_dataset(file1)\n",
    "        ds_v = xr.open_dataset(file2)\n",
    "        udata = ds_u[\"z\"].to_numpy()\n",
    "        vdata = ds_v[\"z\"].to_numpy()\n",
    "\n",
    "        xinc = float(subprocess.check_output(f'gmt grdinfo -M -C {file1} | awk \\'{{print $8}}\\'', shell=True)) * 111.000 * np.cos(np.deg2rad(self._strain_range[2]))\n",
    "        yinc = float(subprocess.check_output(f'gmt grdinfo -M -C {file1} | awk \\'{{print $9}}\\'', shell=True)) * 111.000\n",
    "\n",
    "        exx, eyy, exy, rot, max_shear, dilatation, second_invariant = strain_on_regular_grid(xinc, yinc, udata * 1000, vdata * 1000)\n",
    "        \n",
    "        # Dynamically adjust the coordinates to match the data shape\n",
    "        lat_size, lon_size = max_shear.shape\n",
    "        ydata_adjusted = np.linspace(self._strain_range[2], self._strain_range[3], lat_size)\n",
    "        xdata_adjusted = np.linspace(self._strain_range[0], self._strain_range[1], lon_size)\n",
    "        \n",
    "        # Save the max_shear, dilatation, and second_invariant components as NetCDF files\n",
    "        max_shear_da = xr.DataArray(max_shear, coords=[ydata_adjusted, xdata_adjusted], dims=[\"latitude\", \"longitude\"])\n",
    "        max_shear_ds = xr.Dataset({\"max_shear\": max_shear_da})\n",
    "        max_shear_file = os.path.join(self._tempdir, f\"I{self._grid_inc[0]}_max_shear.nc\")\n",
    "        max_shear_ds.to_netcdf(max_shear_file)\n",
    "        \n",
    "        dilatation_da = xr.DataArray(dilatation, coords=[ydata_adjusted, xdata_adjusted], dims=[\"latitude\", \"longitude\"])\n",
    "        dilatation_ds = xr.Dataset({\"dilatation\": dilatation_da})\n",
    "        dilatation_file = os.path.join(self._tempdir, f\"I{self._grid_inc[0]}_dilatation.nc\")\n",
    "        dilatation_ds.to_netcdf(dilatation_file)\n",
    "        \n",
    "        second_invariant_da = xr.DataArray(second_invariant, coords=[ydata_adjusted, xdata_adjusted], dims=[\"latitude\", \"longitude\"])\n",
    "        second_invariant_ds = xr.Dataset({\"second_invariant\": second_invariant_da})\n",
    "        second_invariant_file = os.path.join(self._tempdir, f\"I{self._grid_inc[0]}_second_invariant.nc\")\n",
    "        second_invariant_ds.to_netcdf(second_invariant_file)\n",
    "\n",
    "        print(\"Success computing strain via gpsgridder method.\")\n",
    "        return udata, vdata, abs(rot), exx, exy, eyy, max_shear, dilatation, second_invariant\n",
    "\n",
    "# Read the configuration file\n",
    "grid_sizes = [0.1, 0.3, 0.5]\n",
    "\n",
    "for grid_size in grid_sizes:\n",
    "    params = {\n",
    "        'inc': [grid_size, grid_size],\n",
    "        'range_strain': [95, 98, 16, 28],\n",
    "        'range_data': [95, 98, 16, 28],\n",
    "        'xdata': np.linspace(95, 98, int((98 - 95) / grid_size) + 1),  # Ensure it matches the grid size\n",
    "        'ydata': np.linspace(16, 28, int((28 - 16) / grid_size) + 1),  # Ensure it matches the grid size\n",
    "        'outdir': 'Output_gpsgridder',\n",
    "        'method_specific': {\n",
    "            'poisson': 0.5,\n",
    "            'fd': 0.01,\n",
    "            'eigenvalue': 0.0001\n",
    "        }\n",
    "    }\n",
    "\n",
    "    # Ensure the output directory exists\n",
    "    if not os.path.exists(params['outdir']):\n",
    "        os.makedirs(params['outdir'])\n",
    "\n",
    "    # Read the velocity field data\n",
    "    input_file = '/Users/zuhair/Library/CloudStorage/OneDrive-NanyangTechnologicalUniversity/Research/current-projects/strain-rate-seismicity/data/mymr_vel_space_ITRF2014.txt'\n",
    "    vel_field_data = pd.read_csv(input_file, delim_whitespace=True, names=['Lon', 'Lat', 'Ve', 'Vn', 'Vu', 'Se', 'Sn', 'Su', 'Name'])\n",
    "\n",
    "    # Convert columns to numeric\n",
    "    vel_field_data['Lon'] = pd.to_numeric(vel_field_data['Lon'], errors='coerce')\n",
    "    vel_field_data['Lat'] = pd.to_numeric(vel_field_data['Lat'], errors='coerce')\n",
    "\n",
    "    # Initialize and compute strain using gpsgridder\n",
    "    strain_model = gpsgridder(params)\n",
    "    max_shear_grd = strain_model.compute(vel_field_data)\n",
    "\n",
    "    # The max_shear.nc file should now be saved in the output directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad70dc12-9aee-4385-b544-26f225b19bf3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot the results\n",
    "fig, axes = plt.subplots(1, len(grid_sizes), dpi = 300, figsize=(20, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "\n",
    "for ax, grid_size in zip(axes, grid_sizes):\n",
    "    max_shear_file = os.path.join('Output_gpsgridder', f'I{grid_size}_max_shear.nc')\n",
    "    ds = xr.open_dataset(max_shear_file)\n",
    "    max_shear = ds['max_shear']\n",
    "\n",
    "    # Plot the max shear strain\n",
    "    c = ax.pcolormesh(max_shear['longitude'], max_shear['latitude'], max_shear, transform=ccrs.PlateCarree(), cmap='Blues')\n",
    "    ax.coastlines(resolution='10m', color='black', linewidth=0.3)\n",
    "    ax.set_title(f'{grid_size}˚x{grid_size}˚')\n",
    "    gl = ax.gridlines(draw_labels=True, color='gray', alpha=0.1, linestyle='-')\n",
    "    gl.top_labels = False\n",
    "    gl.right_labels = False\n",
    "    gl.xlabel_style = {'size': 10, 'color': 'black', 'rotation': 0}\n",
    "    gl.ylabel_style = {'size': 10, 'color': 'black'}\n",
    "\n",
    "# Add a single colorbar for all subplots\n",
    "fig.colorbar(c, ax=axes.ravel().tolist(), orientation='vertical', pad=0.02, aspect=50, label='Max Shear Strain')\n",
    "\n",
    "# # Save the figure to an 'output' folder\n",
    "# output_dir = 'output'\n",
    "# if not os.path.exists(output_dir):\n",
    "#     os.makedirs(output_dir)\n",
    "# plt.savefig(os.path.join(output_dir, 'strain_rate_comparison.png'), bbox_inches='tight')\n",
    "\n",
    "# Display the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763aa153",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
